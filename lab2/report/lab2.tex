\documentclass[12pt]{article}
\usepackage[paper=letterpaper,margin=2cm]{geometry}
\usepackage{fancyhdr}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{blindtext}
\usepackage{xcolor}
\usepackage{indentfirst}
\usepackage{listings}
\usepackage[colorlinks=true]{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=blue,
    citecolor=blue,
    pdftitle={Relatório OC Laboratório 2 2023/2024},
    pdfpagemode=FullScreen,
}

\pagestyle{fancy}
\fancyhf{}
\rhead{Grupo \textbf{43}}
\lhead{Relatório OC Laboratório 2 2023/2024 LEIC-A}
\cfoot{Gonçalo Bárias (103124), Miguel Costa (103969) e Raquel Braunschweig (102624)}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

\begin{document}

    \section{General Code Context}
    
    \subsection{Address Decomposition}
    To compute the address decomposition in every file we used the following code:

    \begin{verbatim}
        tag = address / (L1_N_LINES * BLOCK_SIZE);
        index = (address / BLOCK_SIZE) % L1_N_LINES;
        offset = address % BLOCK_SIZE;
    \end{verbatim}

    The division operation acts as a left shift, removiong lower bits from the address. The remainder operation helps us 
     isolate the lower-order bits.

    So, to find the \textit{tag}, we first need to remove the lower bits related to the \textit{index} and \textit{offset}. 
    
    For the \textit{index}, we start by subtracting the \textit{offset} bits. Then, we apply the remainder operation using the number of lines, 
     which gives us the \textit{index} bits.
     
    As for the \textit{offset}, we use the remainder operation with the block size to obtain the \textit{offset} bits.

    \subsection{Write-back Policy}
    To implement the write-back policy, we utilize a the following parameter:

    \begin{verbatim}
        L1[index].Dirty = 0;
        L1[index].Dirty = 1;
    \end{verbatim}

    When the \texttt{Dirty} parameter is set to 1, it indicates that the information must be written to either the RAM or the L2 cache (depending on the function and exercise).
     After writing, we reset this parameter to 0 to prevent inadvertent duplicate writes. Conversely, we set it to 1 when a write operation has just been performed on 
     the record.

    \section{Directly-Mapped L1 Cache}\label{L1_cache}

    In this task, we develop a memory hierarchy with an L1 direct mapped cache with multiple lines with the parameters provided in the constant file.
    
    We started by changing the L1Cache header, adding an additional constant (L1\_N\_LINES) that calculates the number of lines available in this cache.
     We also added an array to the struct of the CacheL1 that will save all the data that is written onto it.

    In the code file, we start by creating an array for the memory data, and our L1Cache. After that, the initCache function
     will set all the valid, dirty and tag bits, and data to 0. When acessing the L1Cache, the adress is splitted into tag, index, and offset.
     Using the obtained index, The acessL1 function will then verify the value of the valid bit and compare the obtained tag with the tag 
     in the cache array. If the valid bit is set to 1 (there is data in the location we want to acess) and the tags are the same, the function 
     will either read the data from the cache or write the data in the cache, setting the Dirty bit to 1. 

    If the valid bit is set to 0 (there is no data written) or the tags are not the same, the function will verify the
     value of the dirty bit. If the dirty bit is set to 1, the cache data is saved into memory. Finally, the function will , again,
     read the data from the cache or write the data onto the cache, updating the dirty bit to either 0 or 1 (respectively), the tag to the given one
     and setting the valid bit to 1.

    \section{Directly-Mapped L2 Cache}

    In accordance with the provided instructions, we opted to repurpose the cache outlined in section 1 to serve as our L1 cache.

    In order to simplify the initialization process for both the caches and the RAM, we consolidated these tasks into the \texttt{init\_caches} 
     function. Subsequently, for the setup of the L2 cache, we followed the same protocol as outlined for the L1 cache, detailed in section 1.

    Regarding the \texttt{accessL1} function, minimal alterations were made, primarily involving rerouting it to access the L2 cache rather than directly
     interfacing with the RAM in the event of a cache miss or a dirty block.

    The implementation of the L2 cache was a relatively straightforward process. We essentially duplicated the \texttt{accessL1} function, named it \texttt{accessL2} and,
     instead of re-routing to the L2 cache, we directed it to interact with the RAM. If additional clarity on the \texttt{accessL1} function is needed, the section above 
     details how this funcion works.


    \section{2-Way L2 Cache}

    Blah
\end{document}
